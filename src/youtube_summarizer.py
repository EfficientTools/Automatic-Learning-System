"""
R√©sumeur de vid√©os YouTube
Traite les flux RSS YouTube et g√©n√®re des r√©sum√©s IA
"""

import feedparser
import requests
from openai import OpenAI
from datetime import datetime, timedelta
from typing import List, Dict, Any
from dataclasses import dataclass
import re
import time
import html

@dataclass
class VideoSummary:
    """Structure de donn√©es pour un r√©sum√© de vid√©o"""
    title: str
    summary: str
    url: str
    published: datetime
    source: str
    channel_name: str

class YouTubeSummarizer:
    """R√©sumeur de vid√©os YouTube utilisant l'IA"""
    
    def __init__(self, config):
        self.config = config
        self.client = OpenAI(api_key=config.openai_api_key) if config.openai_api_key else None
    
    def process_videos(self) -> List[VideoSummary]:
        """Traiter les vid√©os des cha√Ænes YouTube"""
        if not self.client:
            print("‚ö†Ô∏è Cl√© API OpenAI non configur√©e, r√©sum√©s de vid√©os ignor√©s")
            return []
        
        if not self.config.youtube_channels:
            print("‚ÑπÔ∏è Aucune cha√Æne YouTube configur√©e")
            return []
        
        all_summaries = []
        
        for channel_id in self.config.youtube_channels:
            try:
                print(f"üé• Traitement de la cha√Æne YouTube: {channel_id}")
                summaries = self.process_channel(channel_id)
                all_summaries.extend(summaries)
                time.sleep(2)  # Limitation du taux
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors du traitement de la cha√Æne {channel_id}: {e}")
                continue
        
        # Trier par date de publication (plus r√©cent en premier)
        all_summaries.sort(key=lambda x: x.published, reverse=True)
        
        return all_summaries[:self.config.max_video_summaries]
    
    def process_channel(self, channel_id: str) -> List[VideoSummary]:
        """Traiter une seule cha√Æne YouTube"""
        # URL du flux RSS YouTube
        rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }
            response = requests.get(rss_url, headers=headers, timeout=10)
            feed = feedparser.parse(response.content)
        except Exception as e:
            print(f"‚ö†Ô∏è √âchec du parsing du RSS YouTube pour la cha√Æne {channel_id}: {e}")
            return []
        
        if not feed.entries:
            print(f"‚ö†Ô∏è Aucune vid√©o trouv√©e pour la cha√Æne: {channel_id}")
            return []
        
        channel_name = feed.feed.get('title', f'Cha√Æne {channel_id}')
        summaries = []
        
        # Date limite (vid√©os r√©centes uniquement)
        cutoff_date = datetime.now() - timedelta(days=self.config.days_lookback)
        
        for entry in feed.entries[:2]:  # Max 2 vid√©os par cha√Æne
            try:
                # Parser la date de publication
                published = datetime.now()
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    published = datetime(*entry.published_parsed[:6])
                
                # Ignorer les vid√©os trop anciennes
                if published < cutoff_date:
                    continue
                
                # Obtenir les m√©tadonn√©es de la vid√©o
                video_url = entry.link
                video_title = self.clean_text(entry.title)
                video_description = self.clean_text(entry.get('summary', ''))
                
                # G√©n√©rer le r√©sum√© avec l'IA
                summary = self.generate_video_summary(video_title, video_description)
                
                if summary:
                    video_summary = VideoSummary(
                        title=video_title,
                        summary=summary,
                        url=video_url,
                        published=published,
                        source="YouTube",
                        channel_name=channel_name
                    )
                    summaries.append(video_summary)
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors du traitement de la vid√©o: {e}")
                continue
        
        return summaries
    
    def generate_video_summary(self, title: str, description: str) -> str:
        """G√©n√©rer un r√©sum√© IA du contenu vid√©o"""
        try:
            prompt = f"""
            Cr√©ez un r√©sum√© concis (2-3 paragraphes) de cette vid√©o YouTube bas√© sur son titre et sa description.
            Concentrez-vous sur les points cl√©s et les enseignements principaux qui seraient pr√©cieux pour l'apprentissage.
            R√©pondez en fran√ßais et soyez informatif mais concis.
            
            Titre de la vid√©o: {title}
            
            Description: {description[:800]}...
            
            R√©sum√©:
            """
            
            response = self.client.chat.completions.create(
                model=self.config.openai_model,
                messages=[
                    {"role": "system", "content": "Vous √™tes un assistant qui cr√©e des r√©sum√©s concis et informatifs de contenu √©ducatif en fran√ßais."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=250,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la g√©n√©ration du r√©sum√©: {e}")
            return f"R√©sum√© non disponible. Vid√©o: {title}"
    
    def clean_text(self, text: str) -> str:
        """Nettoyer un texte"""
        if not text:
            return ""
        
        text = html.unescape(text)
        text = re.sub(r'<[^>]+>', '', text)  # Supprimer les balises HTML
        text = re.sub(r'\s+', ' ', text)     # Nettoyer les espaces
        return text.strip()
